{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import sent_tokenize\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "import re\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences/sentence/0/text</th>\n",
       "      <th>sentences/sentence/0/_id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>aspects</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentences/sentence/1/_id</th>\n",
       "      <th>sentences.1</th>\n",
       "      <th>aspects.1</th>\n",
       "      <th>polarity.1</th>\n",
       "      <th>sentences/sentence/2/_id</th>\n",
       "      <th>...</th>\n",
       "      <th>sentences/sentence/7/Opinions/Opinion/2/_polarity</th>\n",
       "      <th>sentences/sentence/16/_OutOfScope</th>\n",
       "      <th>sentences/sentence/20/_OutOfScope</th>\n",
       "      <th>sentences/sentence/17/_OutOfScope</th>\n",
       "      <th>sentences/sentence/9/Opinions/Opinion/2/_category</th>\n",
       "      <th>sentences/sentence/9/Opinions/Opinion/2/_polarity</th>\n",
       "      <th>sentences/sentence/11/_OutOfScope</th>\n",
       "      <th>sentences/sentence/14/_OutOfScope</th>\n",
       "      <th>sentences/sentence/2/Opinions/Opinion/4/_category</th>\n",
       "      <th>sentences/sentence/2/Opinions/Opinion/4/_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Being a PC user my whole life....</td>\n",
       "      <td>79:00:00</td>\n",
       "      <td>This computer is absolutely AMAZING!!!</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td>79:01:00</td>\n",
       "      <td>10 plus hours of battery...</td>\n",
       "      <td>BATTERY#OPERATION_PERFORMANCE</td>\n",
       "      <td>positive</td>\n",
       "      <td>79:02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the laptop was really good and it goes really ...</td>\n",
       "      <td>10:00</td>\n",
       "      <td>i would really recommend to any person out the...</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td>10:01</td>\n",
       "      <td>and its really cheap and you wont regret buyin...</td>\n",
       "      <td>LAPTOP#PRICE</td>\n",
       "      <td>positive</td>\n",
       "      <td>10:02</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a lifelong Windows user, I was extremely pl...</td>\n",
       "      <td>264:00:00</td>\n",
       "      <td>As a computer science student in college, I fi...</td>\n",
       "      <td>LAPTOP#PORTABILITY</td>\n",
       "      <td>positive</td>\n",
       "      <td>264:01:00</td>\n",
       "      <td>without a big ol' clunky machine in my backpac...</td>\n",
       "      <td>LAPTOP#DESIGN_FEATURES</td>\n",
       "      <td>positive</td>\n",
       "      <td>264:02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oh my goodness-I am not a happy camper.</td>\n",
       "      <td>24:00:00</td>\n",
       "      <td>My HP is very heavy.</td>\n",
       "      <td>LAPTOP#DESIGN_FEATURES</td>\n",
       "      <td>negative</td>\n",
       "      <td>24:01:00</td>\n",
       "      <td>Not easy to carry.</td>\n",
       "      <td>LAPTOP#PORTABILITY</td>\n",
       "      <td>negative</td>\n",
       "      <td>24:02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Since I purchased my Toshiba netbook, I have b...</td>\n",
       "      <td>277:00:00</td>\n",
       "      <td>The netbook is easier for me to take to bed an...</td>\n",
       "      <td>LAPTOP#PORTABILITY</td>\n",
       "      <td>positive</td>\n",
       "      <td>277:01:00</td>\n",
       "      <td>The screen takes some getting use to, because ...</td>\n",
       "      <td>DISPLAY#USABILITY</td>\n",
       "      <td>neutral</td>\n",
       "      <td>277:02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>This laptop is amazing!</td>\n",
       "      <td>B00KB3MXH4_22_A106YGESUYA4BP:0</td>\n",
       "      <td>Windows 8.1 has its pros and cons.</td>\n",
       "      <td>OS#GENERAL</td>\n",
       "      <td>neutral</td>\n",
       "      <td>B00KB3MXH4_22_A106YGESUYA4BP:1</td>\n",
       "      <td>The keyboard is backlit but you have to press ...</td>\n",
       "      <td>KEYBOARD#DESIGN_FEATURES</td>\n",
       "      <td>positive</td>\n",
       "      <td>B00KB3MXH4_22_A106YGESUYA4BP:2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>The HP Envy 15 has been everything I expected.</td>\n",
       "      <td>B00D7Z84OY_46_A1P70MSK0HHO7K:0</td>\n",
       "      <td>After doing much research for a laptop that ha...</td>\n",
       "      <td>LAPTOP#DESIGN_FEATURES</td>\n",
       "      <td>positive</td>\n",
       "      <td>B00D7Z84OY_46_A1P70MSK0HHO7K:1</td>\n",
       "      <td>Amazon had the best pricing and the delivery w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00D7Z84OY_46_A1P70MSK0HHO7K:2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>used 6 times black screen returned for refund</td>\n",
       "      <td>B00KMRGF28_304_A35Q7MBKQZV1SA:0</td>\n",
       "      <td>do not use the facial recognition</td>\n",
       "      <td>SOFTWARE#GENERAL</td>\n",
       "      <td>negative</td>\n",
       "      <td>B00KMRGF28_304_A35Q7MBKQZV1SA:1</td>\n",
       "      <td>Windows 8 is not supported by a lot of things!</td>\n",
       "      <td>OS#USABILITY</td>\n",
       "      <td>negative</td>\n",
       "      <td>B00KMRGF28_304_A35Q7MBKQZV1SA:2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>The Dell is quick enough, sturdy, not good wit...</td>\n",
       "      <td>B00KMRGF28_143_A2F0D5EV8ZOK44:0</td>\n",
       "      <td>It does what it advertises.</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td>B00KMRGF28_143_A2F0D5EV8ZOK44:1</td>\n",
       "      <td>Price is great, wish it didn't have Windows 8,...</td>\n",
       "      <td>LAPTOP#PRICE</td>\n",
       "      <td>positive</td>\n",
       "      <td>B00KMRGF28_143_A2F0D5EV8ZOK44:2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>I bought this for my daughter to use for schoo...</td>\n",
       "      <td>B00KMRGF28_302_A149BES2K4UIY1:0</td>\n",
       "      <td>Love the price too!</td>\n",
       "      <td>LAPTOP#PRICE</td>\n",
       "      <td>positive</td>\n",
       "      <td>B00KMRGF28_302_A149BES2K4UIY1:1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sentences/sentence/0/text  \\\n",
       "0                    Being a PC user my whole life....   \n",
       "1    the laptop was really good and it goes really ...   \n",
       "2    As a lifelong Windows user, I was extremely pl...   \n",
       "3              Oh my goodness-I am not a happy camper.   \n",
       "4    Since I purchased my Toshiba netbook, I have b...   \n",
       "..                                                 ...   \n",
       "445                            This laptop is amazing!   \n",
       "446     The HP Envy 15 has been everything I expected.   \n",
       "447      used 6 times black screen returned for refund   \n",
       "448  The Dell is quick enough, sturdy, not good wit...   \n",
       "449  I bought this for my daughter to use for schoo...   \n",
       "\n",
       "            sentences/sentence/0/_id  \\\n",
       "0                           79:00:00   \n",
       "1                              10:00   \n",
       "2                          264:00:00   \n",
       "3                           24:00:00   \n",
       "4                          277:00:00   \n",
       "..                               ...   \n",
       "445   B00KB3MXH4_22_A106YGESUYA4BP:0   \n",
       "446   B00D7Z84OY_46_A1P70MSK0HHO7K:0   \n",
       "447  B00KMRGF28_304_A35Q7MBKQZV1SA:0   \n",
       "448  B00KMRGF28_143_A2F0D5EV8ZOK44:0   \n",
       "449  B00KMRGF28_302_A149BES2K4UIY1:0   \n",
       "\n",
       "                                             sentences  \\\n",
       "0               This computer is absolutely AMAZING!!!   \n",
       "1    i would really recommend to any person out the...   \n",
       "2    As a computer science student in college, I fi...   \n",
       "3                                 My HP is very heavy.   \n",
       "4    The netbook is easier for me to take to bed an...   \n",
       "..                                                 ...   \n",
       "445                 Windows 8.1 has its pros and cons.   \n",
       "446  After doing much research for a laptop that ha...   \n",
       "447                  do not use the facial recognition   \n",
       "448                        It does what it advertises.   \n",
       "449                                Love the price too!   \n",
       "\n",
       "                    aspects  polarity         sentences/sentence/1/_id  \\\n",
       "0            LAPTOP#GENERAL  positive                         79:01:00   \n",
       "1            LAPTOP#GENERAL  positive                            10:01   \n",
       "2        LAPTOP#PORTABILITY  positive                        264:01:00   \n",
       "3    LAPTOP#DESIGN_FEATURES  negative                         24:01:00   \n",
       "4        LAPTOP#PORTABILITY  positive                        277:01:00   \n",
       "..                      ...       ...                              ...   \n",
       "445              OS#GENERAL   neutral   B00KB3MXH4_22_A106YGESUYA4BP:1   \n",
       "446  LAPTOP#DESIGN_FEATURES  positive   B00D7Z84OY_46_A1P70MSK0HHO7K:1   \n",
       "447        SOFTWARE#GENERAL  negative  B00KMRGF28_304_A35Q7MBKQZV1SA:1   \n",
       "448          LAPTOP#GENERAL  positive  B00KMRGF28_143_A2F0D5EV8ZOK44:1   \n",
       "449            LAPTOP#PRICE  positive  B00KMRGF28_302_A149BES2K4UIY1:1   \n",
       "\n",
       "                                           sentences.1  \\\n",
       "0                          10 plus hours of battery...   \n",
       "1    and its really cheap and you wont regret buyin...   \n",
       "2    without a big ol' clunky machine in my backpac...   \n",
       "3                                   Not easy to carry.   \n",
       "4    The screen takes some getting use to, because ...   \n",
       "..                                                 ...   \n",
       "445  The keyboard is backlit but you have to press ...   \n",
       "446  Amazon had the best pricing and the delivery w...   \n",
       "447     Windows 8 is not supported by a lot of things!   \n",
       "448  Price is great, wish it didn't have Windows 8,...   \n",
       "449                                                NaN   \n",
       "\n",
       "                         aspects.1 polarity.1  \\\n",
       "0    BATTERY#OPERATION_PERFORMANCE   positive   \n",
       "1                     LAPTOP#PRICE   positive   \n",
       "2           LAPTOP#DESIGN_FEATURES   positive   \n",
       "3               LAPTOP#PORTABILITY   negative   \n",
       "4                DISPLAY#USABILITY    neutral   \n",
       "..                             ...        ...   \n",
       "445       KEYBOARD#DESIGN_FEATURES   positive   \n",
       "446                            NaN        NaN   \n",
       "447                   OS#USABILITY   negative   \n",
       "448                   LAPTOP#PRICE   positive   \n",
       "449                            NaN        NaN   \n",
       "\n",
       "            sentences/sentence/2/_id  ...  \\\n",
       "0                           79:02:00  ...   \n",
       "1                              10:02  ...   \n",
       "2                          264:02:00  ...   \n",
       "3                           24:02:00  ...   \n",
       "4                          277:02:00  ...   \n",
       "..                               ...  ...   \n",
       "445   B00KB3MXH4_22_A106YGESUYA4BP:2  ...   \n",
       "446   B00D7Z84OY_46_A1P70MSK0HHO7K:2  ...   \n",
       "447  B00KMRGF28_304_A35Q7MBKQZV1SA:2  ...   \n",
       "448  B00KMRGF28_143_A2F0D5EV8ZOK44:2  ...   \n",
       "449                              NaN  ...   \n",
       "\n",
       "    sentences/sentence/7/Opinions/Opinion/2/_polarity  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "445                                               NaN   \n",
       "446                                               NaN   \n",
       "447                                               NaN   \n",
       "448                                               NaN   \n",
       "449                                               NaN   \n",
       "\n",
       "    sentences/sentence/16/_OutOfScope sentences/sentence/20/_OutOfScope  \\\n",
       "0                                 NaN                               NaN   \n",
       "1                                 NaN                               NaN   \n",
       "2                                 NaN                               NaN   \n",
       "3                                 NaN                               NaN   \n",
       "4                                 NaN                               NaN   \n",
       "..                                ...                               ...   \n",
       "445                               NaN                               NaN   \n",
       "446                               NaN                               NaN   \n",
       "447                               NaN                               NaN   \n",
       "448                               NaN                               NaN   \n",
       "449                               NaN                               NaN   \n",
       "\n",
       "    sentences/sentence/17/_OutOfScope  \\\n",
       "0                                 NaN   \n",
       "1                                 NaN   \n",
       "2                                 NaN   \n",
       "3                                 NaN   \n",
       "4                                 NaN   \n",
       "..                                ...   \n",
       "445                               NaN   \n",
       "446                               NaN   \n",
       "447                               NaN   \n",
       "448                               NaN   \n",
       "449                               NaN   \n",
       "\n",
       "    sentences/sentence/9/Opinions/Opinion/2/_category  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "445                                               NaN   \n",
       "446                                               NaN   \n",
       "447                                               NaN   \n",
       "448                                               NaN   \n",
       "449                                               NaN   \n",
       "\n",
       "    sentences/sentence/9/Opinions/Opinion/2/_polarity  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "445                                               NaN   \n",
       "446                                               NaN   \n",
       "447                                               NaN   \n",
       "448                                               NaN   \n",
       "449                                               NaN   \n",
       "\n",
       "    sentences/sentence/11/_OutOfScope sentences/sentence/14/_OutOfScope  \\\n",
       "0                                 NaN                               NaN   \n",
       "1                                 NaN                               NaN   \n",
       "2                                 NaN                               NaN   \n",
       "3                                 NaN                               NaN   \n",
       "4                                 NaN                               NaN   \n",
       "..                                ...                               ...   \n",
       "445                               NaN                               NaN   \n",
       "446                               NaN                               NaN   \n",
       "447                               NaN                               NaN   \n",
       "448                               NaN                               NaN   \n",
       "449                               NaN                               NaN   \n",
       "\n",
       "    sentences/sentence/2/Opinions/Opinion/4/_category  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "445                                               NaN   \n",
       "446                                               NaN   \n",
       "447                                               NaN   \n",
       "448                                               NaN   \n",
       "449                                               NaN   \n",
       "\n",
       "    sentences/sentence/2/Opinions/Opinion/4/_polarity  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "..                                                ...  \n",
       "445                                               NaN  \n",
       "446                                               NaN  \n",
       "447                                               NaN  \n",
       "448                                               NaN  \n",
       "449                                               NaN  \n",
       "\n",
       "[450 rows x 199 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read Dataset\n",
    "data = pd.read_csv('Train SemEval 2015 Task 12.csv')\n",
    "test = pd.read_csv('Test SemEval 2015 Task 12.csv')\n",
    "data1 = pd.read_csv('Train extended.csv')\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemmer and lemmatizer \n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stopwords = [ \"hmm\",\"ok\",\"th\",\"rd\",\"th\",\"nd\",\"!\",\"#\",\"$\",\"%\",\"&\",\"'\",\"’\",\"u\",\"v\",\"b\",\"r\",\"(\",\")\",\"*\",\"+\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\"=\",\">\",\"?\",\"@\",\"[\",\"/\",\"]\",\"^\",\"_\",\"`\",\"{\",\"|\",\"}\",\"~\",\",\",\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\",\"please\",\"sorry\",\"bye\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\",\"hello\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviews and Aspect Labels\n",
    "train_sen1 = data.iloc[:,0]\n",
    "train_sen2 = data.iloc[:,3]\n",
    "train_sen3 = data.iloc[:,6]\n",
    "train_sen4 = data1.iloc[:,2]\n",
    "train_sen5 = data1.iloc[:,6]\n",
    "test_sen = test.iloc[:,10]\n",
    "test_aspect = test.iloc[:,11]\n",
    "aspect_sen1 = data.iloc[:,1]\n",
    "aspect_sen2 = data.iloc[:,4]\n",
    "aspect_sen3 = data.iloc[:,7]\n",
    "aspect_sen4 = data1.iloc[:,3]\n",
    "aspect_sen5 = data1.iloc[:,7]\n",
    "aspect_sen = aspect_sen1.append(aspect_sen2)\n",
    "aspect_sen = aspect_sen.append(aspect_sen3)\n",
    "aspect_sen = aspect_sen.append(aspect_sen4)\n",
    "aspect_sen = aspect_sen.append(aspect_sen5)\n",
    "aspects = aspect_sen.append(test_aspect)\n",
    "train_sen = train_sen1.append(train_sen2)\n",
    "train_sen = train_sen.append(train_sen3)\n",
    "train_sen = train_sen.append(train_sen4)\n",
    "train_sen = train_sen.append(train_sen5)\n",
    "train_sen = train_sen.astype(str)\n",
    "test_sen = test_sen.astype(str)\n",
    "aspects = aspects.astype(str)\n",
    "aspects = aspects.astype('category')\n",
    "aspects = aspects.cat.codes\n",
    "aspects_train = aspects[:1731]\n",
    "aspects_test = aspects[1731:]\n",
    "aspects_train = np.asarray(aspects_train)\n",
    "aspects_test = np.asarray(aspects_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      3\n",
       "2      0\n",
       "3      1\n",
       "4      3\n",
       "      ..\n",
       "168    3\n",
       "169    0\n",
       "170    1\n",
       "171    3\n",
       "172    0\n",
       "Length: 1904, dtype: int8"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentiment Labels\n",
    "lab_train1 = data.iloc[:,2]\n",
    "lab_train2 = data.iloc[:,5]\n",
    "lab_train3 = data.iloc[:,8]\n",
    "lab_train4 = data1.iloc[:,4]\n",
    "lab_train5 = data1.iloc[:,8]\n",
    "lab_train = lab_train1.append(lab_train2)\n",
    "lab_train = lab_train.append(lab_train3)\n",
    "lab_train = lab_train.append(lab_train4)\n",
    "lab_train = lab_train.append(lab_train5)\n",
    "lab_test = test.iloc[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      a\n",
      "0     [('pc', 'NN'), ('user', 'NN'), ('whole', 'JJ')...\n",
      "1     [('laptop', 'JJ'), ('realli', 'NN'), ('good', ...\n",
      "2     [('lifelong', 'RB'), ('window', 'WRB'), ('user...\n",
      "3     [('oh', 'RB'), ('goodness-i', 'NN'), ('not', '...\n",
      "4     [('sinc', 'NN'), ('purchas', 'NN'), ('toshiba'...\n",
      "...                                                 ...\n",
      "1726  [('keyboard', 'NN'), ('backlit', 'NN'), ('pres...\n",
      "1727  [('amazon', 'RB'), ('best', 'JJS'), ('price', ...\n",
      "1728  [('window', 'NN'), ('not', 'RB'), ('support', ...\n",
      "1729  [('price', 'NN'), ('great', 'JJ'), ('wish', 'J...\n",
      "1730                                    [('nan', 'NN')]\n",
      "\n",
      "[1731 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#Data Structure\n",
    "sen=[]\n",
    "for x in train_sen:\n",
    "    #Sentence Tokenization\n",
    "    sentence = sent_tokenize(x)\n",
    "    \n",
    "    for line in sentence:\n",
    "        \n",
    "        #Convert to lowercase\n",
    "        line=line.lower()\n",
    "        #Remove Digits\n",
    "        line = ''.join(c for c in line if not c.isdigit())\n",
    "        #Word Tokenization\n",
    "        token= nltk.word_tokenize(line)\n",
    "        #Stopword Removal\n",
    "        token=[words for words in token if words not in stopwords]\n",
    "        #Lemmatization\n",
    "        token = [wordnet_lemmatizer.lemmatize(word) for word in token]\n",
    "        #Stemming\n",
    "        token= [snowball_stemmer.stem(word) for word in token]\n",
    "        #POS Tagging\n",
    "        tags = nltk.pos_tag(token)\n",
    "\n",
    "    sen.append(str(tags))\n",
    "    \n",
    "sen = pd.DataFrame(sen)\n",
    "sen = sen.rename(columns={0: \"a\"})\n",
    "print(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    a1\n",
      "0    [('lock', 'NN'), ('search', 'NN'), ('updat', '...\n",
      "1    [('buy', 'VB'), ('high', 'JJ'), ('recommend', ...\n",
      "2                                      [('nan', 'NN')]\n",
      "3    [('solid-st', 'JJ'), ('memori', 'NNS'), ('make...\n",
      "4                                      [('nan', 'NN')]\n",
      "..                                                 ...\n",
      "168  [('keyboard', 'NN'), ('backlit', 'NN'), ('pres...\n",
      "169  [('amazon', 'RB'), ('best', 'JJS'), ('price', ...\n",
      "170  [('window', 'NN'), ('not', 'RB'), ('support', ...\n",
      "171  [('price', 'NN'), ('great', 'JJ'), ('wish', 'J...\n",
      "172                                    [('nan', 'NN')]\n",
      "\n",
      "[173 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#Data Structure\n",
    "sent=[]\n",
    "c=0\n",
    "for x in test_sen:\n",
    "    sentence = sent_tokenize(x)\n",
    "    \n",
    "    for line in sentence:\n",
    "        \n",
    "        #Convert to lowercase\n",
    "        line=line.lower()\n",
    "        #Remove Digits\n",
    "        line = ''.join(c for c in line if not c.isdigit())\n",
    "        #Word Tokenization\n",
    "        token= nltk.word_tokenize(line)\n",
    "        #Stopword Removal\n",
    "        token=[words for words in token if words not in stopwords]\n",
    "        #Lemmatization\n",
    "        token = [wordnet_lemmatizer.lemmatize(word) for word in token]\n",
    "        #Stemming\n",
    "        token= [snowball_stemmer.stem(word) for word in token]\n",
    "        #POS Tagging\n",
    "        tags = nltk.pos_tag(token)\n",
    "        \n",
    "    sent.append(str(tags))\n",
    "sent = pd.DataFrame(sent)\n",
    "sent = sent.rename(columns={0: \"a1\"})\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 471)\t0.6472129509118695\n",
      "  (1, 678)\t0.7623092523195228\n",
      "  (2, 893)\t1.0\n",
      "  (3, 377)\t1.0\n",
      "  (6, 365)\t1.0\n",
      "  (7, 289)\t0.6207264067732229\n",
      "  (7, 365)\t0.6815764588194205\n",
      "  (7, 471)\t0.3874948499239469\n",
      "  (8, 291)\t1.0\n",
      "  (10, 365)\t0.6966923313535964\n",
      "  (10, 471)\t0.39608863670062877\n",
      "  (10, 758)\t0.5981083407792673\n",
      "  (11, 25)\t0.8405102880310843\n",
      "  (11, 471)\t0.5417955848047338\n",
      "  (12, 364)\t0.42823655891112844\n",
      "  (12, 365)\t0.9036666695258576\n",
      "  (13, 318)\t1.0\n",
      "  (15, 34)\t1.0\n",
      "  (16, 743)\t1.0\n",
      "  (17, 365)\t1.0\n",
      "  (21, 365)\t1.0\n",
      "  (26, 622)\t1.0\n",
      "  (27, 471)\t1.0\n",
      "  (28, 471)\t0.41800337835063267\n",
      "  (28, 723)\t0.6968413458159658\n",
      "  :\t:\n",
      "  (1694, 471)\t0.44872394545868\n",
      "  (1694, 689)\t0.5604085360040267\n",
      "  (1696, 297)\t0.7670700853885739\n",
      "  (1696, 901)\t0.6415633126215727\n",
      "  (1701, 562)\t0.6928711067496339\n",
      "  (1701, 698)\t0.7210614602317457\n",
      "  (1702, 540)\t1.0\n",
      "  (1704, 459)\t1.0\n",
      "  (1705, 862)\t1.0\n",
      "  (1707, 471)\t1.0\n",
      "  (1710, 324)\t0.7071067811865475\n",
      "  (1710, 586)\t0.7071067811865475\n",
      "  (1712, 365)\t1.0\n",
      "  (1716, 365)\t0.7662169785040125\n",
      "  (1716, 893)\t0.6425819339603175\n",
      "  (1717, 486)\t1.0\n",
      "  (1719, 865)\t1.0\n",
      "  (1721, 651)\t0.7486295362227262\n",
      "  (1721, 667)\t0.662988550048148\n",
      "  (1723, 538)\t1.0\n",
      "  (1724, 459)\t1.0\n",
      "  (1725, 799)\t1.0\n",
      "  (1726, 459)\t1.0\n",
      "  (1729, 365)\t0.8441527451415564\n",
      "  (1729, 930)\t0.5361027353688606\n"
     ]
    }
   ],
   "source": [
    "#Feature Engineering and Encoding \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "sen_vectors = vectorizer.fit_transform(sen['a'])\n",
    "sent_vectors = vectorizer.transform(sent['a1'])\n",
    "print(train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1.687101s; Prediction time: 0.046865s\n",
      "{'nan': {'precision': 0.9692307692307692, 'recall': 0.8513513513513513, 'f1-score': 0.9064748201438849, 'support': 74}, 'negative': {'precision': 0.8478260869565217, 'recall': 0.9069767441860465, 'f1-score': 0.8764044943820224, 'support': 43}, 'neutral': {'precision': 1.0, 'recall': 0.3333333333333333, 'f1-score': 0.5, 'support': 3}, 'positive': {'precision': 0.8360655737704918, 'recall': 0.9622641509433962, 'f1-score': 0.8947368421052632, 'support': 53}, 'accuracy': 0.8901734104046243, 'macro avg': {'precision': 0.9132806074894457, 'recall': 0.7634813949535318, 'f1-score': 0.7944040391577927, 'support': 173}, 'weighted avg': {'precision': 0.8987923356765516, 'recall': 0.8901734104046243, 'f1-score': 0.888355968674297, 'support': 173}}\n",
      "0.8901734104046243\n"
     ]
    }
   ],
   "source": [
    "#Model SVM with Time Frames for Sentiment Classification \n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "t0 = time.time()\n",
    "classifier_linear.fit(sen_vectors, lab_train)\n",
    "t1 = time.time()\n",
    "prediction_linear = classifier_linear.predict(sent_vectors)\n",
    "t2 = time.time()\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1\n",
    "\n",
    "#Results\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "report = accuracy_score(lab_test, prediction_linear)\n",
    "report1 = classification_report(lab_test, prediction_linear, output_dict=True)\n",
    "print(report1)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 4.984656s; Prediction time: 0.249940s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\envs\\PythonGPU\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, '2': {'precision': 0.75, 'recall': 1.0, 'f1-score': 0.8571428571428571, 'support': 3}, '4': {'precision': 1.0, 'recall': 0.5, 'f1-score': 0.6666666666666666, 'support': 2}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, '7': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1}, '8': {'precision': 1.0, 'recall': 0.6666666666666666, 'f1-score': 0.8, 'support': 3}, '10': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2}, '17': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 3}, '18': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2}, '21': {'precision': 1.0, 'recall': 0.5, 'f1-score': 0.6666666666666666, 'support': 4}, '22': {'precision': 0.7142857142857143, 'recall': 1.0, 'f1-score': 0.8333333333333333, 'support': 10}, '23': {'precision': 0.75, 'recall': 0.8823529411764706, 'f1-score': 0.8108108108108107, 'support': 17}, '24': {'precision': 1.0, 'recall': 0.4444444444444444, 'f1-score': 0.6153846153846153, 'support': 9}, '25': {'precision': 0.9333333333333333, 'recall': 0.9333333333333333, 'f1-score': 0.9333333333333333, 'support': 15}, '26': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1}, '27': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 1}, '28': {'precision': 0.8333333333333334, 'recall': 1.0, 'f1-score': 0.9090909090909091, 'support': 5}, '29': {'precision': 1.0, 'recall': 0.25, 'f1-score': 0.4, 'support': 4}, '34': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1}, '35': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1}, '40': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 3}, '43': {'precision': 1.0, 'recall': 0.6666666666666666, 'f1-score': 0.8, 'support': 3}, '47': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, '50': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1}, '56': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, '58': {'precision': 0.6666666666666666, 'recall': 1.0, 'f1-score': 0.8, 'support': 2}, '60': {'precision': 0.8902439024390244, 'recall': 0.9864864864864865, 'f1-score': 0.9358974358974359, 'support': 74}, 'accuracy': 0.8670520231213873, 'macro avg': {'precision': 0.7513522482163598, 'recall': 0.7082125192419311, 'f1-score': 0.7033926176783319, 'support': 173}, 'weighted avg': {'precision': 0.8556121729673118, 'recall': 0.8670520231213873, 'f1-score': 0.8421707439048479, 'support': 173}}\n",
      "0.8670520231213873\n"
     ]
    }
   ],
   "source": [
    "#Model SVM with Time Frames for Aspect Categorization \n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "t0 = time.time()\n",
    "classifier_linear.fit(sen_vectors, aspects_train)\n",
    "t1 = time.time()\n",
    "prediction_linear = classifier_linear.predict(sent_vectors)\n",
    "t2 = time.time()\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1\n",
    "\n",
    "#Results\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "report = accuracy_score(aspects_test, prediction_linear)\n",
    "report1 = classification_report(aspects_test, prediction_linear, output_dict=True)\n",
    "print(report1)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
